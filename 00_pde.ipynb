{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from nangs.bocos import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDE\n",
    "\n",
    "> This module contains the PDE class with the basic functionality to solve PDEs with NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from nangs.utils import *\n",
    "from nangs.solution import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import numpy as np\n",
    "\n",
    "class PDEDataset(Dataset):\n",
    "    \"Receives a dict of arrays and returns every possible combination of the elements in the arrays\"\n",
    "    def __init__(self, inputs):\n",
    "        # convert dict to array\n",
    "        self.inputs = np.array([inputs[k] for k in inputs])\n",
    "        # length of the dataset (all possible combinations)\n",
    "        self.len = 1\n",
    "        for input in self.inputs:\n",
    "            self.len *= len(input)\n",
    "        # modules\n",
    "        self.mods = []\n",
    "        for i, _ in enumerate(self.inputs):\n",
    "            mod = 1\n",
    "            for j, input in enumerate(self.inputs):\n",
    "                if j < i:\n",
    "                    mod *= len(input)\n",
    "            self.mods.append(mod)  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor([inp[(idx // self.mods[i]) % len(inp)] for i, inp in enumerate(self.inputs)])\n",
    "\n",
    "class PDE:\n",
    "    \"PDE class with basic functionality to solve PDEs with NNs\"\n",
    "    def __init__(self, inputs, outputs, params=None, order=1):\n",
    "        \n",
    "        # check lists of unique strings, non-repeated\n",
    "        checkIsListOfStr(inputs)\n",
    "        checkUnique(inputs)\n",
    "        checkIsListOfStr(outputs)\n",
    "        checkUnique(outputs)\n",
    "        checkNoRepeated(inputs, outputs)\n",
    "        if params:\n",
    "            checkIsListOfStr(params)\n",
    "            checkUnique(params)\n",
    "            checkNoRepeated(inputs, params)\n",
    "            checkNoRepeated(params, outputs)\n",
    "        \n",
    "        # save keys\n",
    "        self.input_keys = inputs\n",
    "        self.output_keys = outputs\n",
    "        self.param_keys = params            \n",
    "        \n",
    "        # initialize values\n",
    "        self.train_inputs = {k: [] for k in self.input_keys}\n",
    "        self.test_inputs = {k: [] for k in self.input_keys}\n",
    "        self.outputs = {k: [] for k in self.output_keys}\n",
    "        self.params = {}\n",
    "        if self.param_keys:\n",
    "            self.params = {k: [] for k in self.param_keys}\n",
    "        \n",
    "        # bocos\n",
    "        self.bocos = []\n",
    "        \n",
    "        self.init = False\n",
    "        self.order = order\n",
    "        self.eval = False\n",
    "\n",
    "    def summary(self):\n",
    "        \"Print a summary of the PDE inputs, outputs, params and bocos.\"\n",
    "        print('inputs (train): ', self.train_inputs)\n",
    "        print('inputs (test): ', self.test_inputs)\n",
    "        print('outputs: ', self.outputs)\n",
    "        if self.params:\n",
    "            print('params: ', self.params)\n",
    "        print('bocos: ', [boco.type for boco in self.bocos])\n",
    "        print('')\n",
    "        \n",
    "    def setValues(self, values, train=True):\n",
    "        self.eval = not train\n",
    "        \"Set values for inputs and params\"\n",
    "        checkValidDict(values)\n",
    "        for key in values:\n",
    "            value = values[key]\n",
    "            if key in self.input_keys: \n",
    "                if train: \n",
    "                    self.train_inputs[key] = value\n",
    "                else: \n",
    "                    self.test_inputs[key] = value\n",
    "            elif key in self.param_keys: \n",
    "                if train:    \n",
    "                    self.params[key] = value\n",
    "                else: \n",
    "                    raise Exception('You cannot set params in test data !')\n",
    "            elif key in self.output_keys:\n",
    "                raise Exception('You cannot set values to outputs !')\n",
    "            else:\n",
    "                raise Exception('Key '+ key +' not found !')\n",
    "                \n",
    "    def addBoco(self, boco):\n",
    "        \"Add a boco to the list of bocos\"\n",
    "        boco.addBoco(self.input_keys, self.output_keys)\n",
    "        self.bocos += [boco]\n",
    "        \n",
    "    def bocoSummary(self):\n",
    "        \"Print summary of each boco\"\n",
    "        for boco in self.bocos: \n",
    "            boco.summary(self.input_keys, self.output_keys, self.param_keys) \n",
    "            \n",
    "    def buildSolution(self, topo):\n",
    "        \"Build an MLP to be the solution to the PDE\"\n",
    "        n_inputs, n_outputs = len(self.input_keys), len(self.output_keys)\n",
    "        self.solution = Solution(n_inputs, n_outputs, topo['layers'], topo['neurons'], topo['activations'])\n",
    "\n",
    "    def compile(self, lr=3e-4, epochs=30, batch_size=32):\n",
    "        \"Set the required parameters for training\"\n",
    "        self.optimizer = torch.optim.Adam(self.solution.parameters(), lr=lr)\n",
    "        self.epochs = epochs\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def solve(self, device, path):\n",
    "        \"Find a solution to the PDE\"\n",
    "        # initialize dataladers\n",
    "        if not self.init: \n",
    "            self.initialize()\n",
    "        # convert params to tensors\n",
    "        params = {k: torch.FloatTensor(self.params[k]).to(device) for k in self.params}\n",
    "        # train loop\n",
    "        self.solution.to(device)\n",
    "        best_loss = 1e8\n",
    "        hist = {'train_loss': [], 'bocos': {boco.name: [] for boco in self.bocos}}\n",
    "        if self.eval:\n",
    "            hist['val_loss'] = []\n",
    "        mb = master_bar(range(1, self.epochs+1))\n",
    "        for epoch in mb:\n",
    "            #train\n",
    "            self.solution.train()\n",
    "            pdes_losses = []\n",
    "            bocos_loss = {boco.name: [] for boco in self.bocos}\n",
    "            for inputs in progress_bar(self.dataloader['train'], parent=mb):\n",
    "                                    \n",
    "                # start accumulating gradients                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # accumulate gradients for each boco\n",
    "                for boco in self.bocos:\n",
    "                    boco_loss = boco.computeLoss(self.solution, device)\n",
    "                    bocos_loss[boco.name].append(boco_loss.item())\n",
    "                    boco_loss.backward()\n",
    "                    \n",
    "                # accumulate gradients for each pde\n",
    "                inputs = inputs.to(device)\n",
    "                inputs.requires_grad = True\n",
    "                outputs = self.solution(inputs)\n",
    "                \n",
    "                # compute gradients of outputs w.r.t. inputs\n",
    "                grads, _inputs, _outputs = self.computeGrads(inputs, outputs)\n",
    "                \n",
    "                # compute loss\n",
    "                loss = self.computePDELoss(grads, _inputs, _outputs, params)\n",
    "                pde_loss = []\n",
    "                for l in loss:\n",
    "                    l = l.pow(2).mean()\n",
    "                    l.backward(retain_graph=True)\n",
    "                    pde_loss.append(l.item())                  \n",
    "                \n",
    "                # update weights\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                mb.child.comment = f'train loss {np.mean(pdes_losses):.5f}'\n",
    "                pdes_losses.append(pde_loss)                    \n",
    "                self.optimizer.zero_grad()              \n",
    "            \n",
    "            pde_total_loss = np.mean(pdes_losses, axis=0)\n",
    "            bocos_total_loss = 0\n",
    "            for boco in self.bocos:\n",
    "                bocos_loss[boco.name] = np.mean(bocos_loss[boco.name])\n",
    "                hist['bocos'][boco.name].append(bocos_loss[boco.name])\n",
    "                bocos_total_loss += bocos_loss[boco.name]\n",
    "            total_loss = np.mean(pde_total_loss) + bocos_total_loss\n",
    "            \n",
    "            hist['train_loss'].append(total_loss)\n",
    "            info = f'Epoch {epoch}/{self.epochs} Losses {total_loss:.5f} \\n PDE  [ '\n",
    "            for l in pde_total_loss:\n",
    "                info += f\"{l:.5f} \"\n",
    "            info += \"] \"\n",
    "            for boco in self.bocos:\n",
    "                info += f'\\n {boco.name} {bocos_loss[boco.name]:.5f}'\n",
    "                \n",
    "            if self.eval:\n",
    "                #evaluate\n",
    "                self.solution.eval()\n",
    "                val_losses = []\n",
    "                for inputs in progress_bar(self.dataloader['val'], parent=mb):\n",
    "                    # compute pde solution\n",
    "                    inputs = inputs.to(device)\n",
    "                    inputs.requires_grad = True\n",
    "                    outputs = self.solution(inputs)\n",
    "                    # compute gradients of outputs w.r.t. inputs\n",
    "                    grads, _inputs, _outputs = self.computeGrads(inputs, outputs)\n",
    "                    # compute loss\n",
    "                    loss = self.computePDELoss(grads, _inputs, _outputs, params)\n",
    "                    #loss can be a single value (one pde) or a list (system of pdes)\n",
    "                    if type(loss) != list:\n",
    "                        loss = [loss]\n",
    "                    val_loss = []\n",
    "                    for l in loss:\n",
    "                        l = l.pow(2).mean()                 \n",
    "                        val_loss.append(l.item())\n",
    "                    val_losses.append(val_loss)\n",
    "                    mb.child.comment = f'val loss {np.mean(val_losses):.5f}'\n",
    "                \n",
    "                # save model if best loss (this does not include bocos losses !!!)\n",
    "                val_total_loss = np.mean(val_losses)\n",
    "                if val_total_loss < best_loss:\n",
    "                    best_loss = total_loss\n",
    "                    torch.save(self.solution.state_dict(), path)\n",
    "            \n",
    "                hist['val_loss'].append(val_total_loss)\n",
    "                info += '\\n Val [ '\n",
    "                for l in np.mean(val_losses, axis=0):\n",
    "                    info += f\"{l:.5f} \"\n",
    "                info += ']'\n",
    "                \n",
    "            mb.write(info)          \n",
    "            #mb.first_bar.comment = f'best acc {best_acc:.5f} at epoch {best_e}'\n",
    "            \n",
    "        return hist\n",
    "                \n",
    "    def initialize(self):\n",
    "        self.dataset = {\n",
    "            'train': PDEDataset(self.train_inputs),\n",
    "            'val': PDEDataset(self.test_inputs)\n",
    "        } \n",
    "        self.dataloader = {\n",
    "            'train': DataLoader(self.dataset['train'], batch_size=self.bs, shuffle=True, num_workers=4),\n",
    "            'val': DataLoader(self.dataset['val'], batch_size=self.bs, shuffle=False, num_workers=4)\n",
    "        }\n",
    "        for boco in self.bocos:\n",
    "            boco.initialize()\n",
    "        self.init = True\n",
    "                        \n",
    "    def computeGrads(self, inputs, outputs):\n",
    "        # init grads\n",
    "        grads = {o: {i: [] for i in self.input_keys} for o in self.output_keys}    \n",
    "        \n",
    "        # save inputs for grads\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        # compute first order derivatives \n",
    "        for i, output in enumerate(self.output_keys):            \n",
    "            _grads = self.computeGrad(outputs[:,i])            \n",
    "            #print(_grads)\n",
    "            # save in dict\n",
    "            for j, inp in enumerate(self.input_keys):\n",
    "                grads[output][inp] = _grads[:,j]                 \n",
    "            \n",
    "            # compute higher order derivatives (only works for second order)\n",
    "            if self.order > 1:                                  \n",
    "                #order = 1\n",
    "                #while order < self.order:\n",
    "                #order += 1 \n",
    "                \n",
    "                order = 2\n",
    "                grads[f'{order}{output}'] = {}\n",
    "                # compute gradients of gradients\n",
    "                for j, inp in enumerate(self.input_keys):\n",
    "                    __grads = self.computeGrad(_grads[:,j])\n",
    "                    # save in dict\n",
    "                    for k, inp2 in enumerate(self.input_keys):\n",
    "                        grads[f'{order}{output}'][f'{inp}{inp2}'] = __grads[:,k]\n",
    "        \n",
    "        # assign keys to inputs\n",
    "        # DOING THIS BREAKS GRADIENTS\n",
    "        _inputs = {inp: inputs[:,i] for i, inp in enumerate(self.input_keys)}\n",
    "        \n",
    "        # assign keys to outputs\n",
    "        _outputs = {o: outputs[:,i] for i, o in enumerate(self.output_keys)}\n",
    "        \n",
    "        return grads, _inputs, _outputs\n",
    "    \n",
    "    def computeGrad(self, outputs, input_key=None):\n",
    "        # torch.autograd.grad -> Computes and returns the sum of gradients of outputs w.r.t. the inputs.\n",
    "        _grads, = torch.autograd.grad(outputs, self.inputs, \n",
    "                        grad_outputs=outputs.data.new(outputs.shape).fill_(1),\n",
    "                        create_graph=True, only_inputs=True)\n",
    "        if input_key:\n",
    "            k = self.input_keys.index(input_key)\n",
    "            return _grads[:,k]\n",
    "        return _grads\n",
    "                        \n",
    "    def computePDELoss(self, grads, inputs, outputs, params):\n",
    "        print('This function has to be overloaded by a child class!')\n",
    "        \n",
    "    def load_state_dict(self, path):\n",
    "        self.solution.load_state_dict(torch.load(path))\n",
    "        \n",
    "    def evaluate(self, inputs, device):\n",
    "        \"Evaluate solution\"\n",
    "        checkValidDict(inputs)\n",
    "        checkDictArray(inputs, self.input_keys)\n",
    "        # set values of inpenedent vars \n",
    "        for key in self.input_keys: \n",
    "            if key in inputs: \n",
    "                self.test_inputs[key] = inputs[key] \n",
    "            else: \n",
    "                raise Exception(key + ' is not an input')\n",
    "        # build dataset\n",
    "        dataset = PDEDataset(self.test_inputs)\n",
    "        outputs = []\n",
    "        self.solution.eval()\n",
    "        for i in range(len(dataset)):\n",
    "            input = dataset[i].to(device)\n",
    "            outputs.append(self.solution(input).cpu().detach().numpy())\n",
    "        outputs = np.array(outputs)\n",
    "        for i, k in enumerate(self.output_keys):\n",
    "            self.outputs[k] = outputs[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['x', 't'], outputs=['p'], params=['u'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*inputs*, *outputs* and *params* must be lists of strings with non-repeated elements or you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pde = PDE(inputs=['x', 't'], outputs=['x'], params=['u'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Repeated item x\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "pde = PDE(['a'], ['b'])\n",
    "pde = PDE(inputs=['a'], outputs=['b'])\n",
    "pde = PDE(inputs=['a', 'b', 'c'], outputs=['d'])\n",
    "pde = PDE(inputs=['a'], outputs=['b', 'c', 'd'])\n",
    "pde = PDE(inputs=['a'], outputs=['b'], params=['c'])\n",
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d', 'e', 'f'])\n",
    "\n",
    "try:\n",
    "    pde = PDE(inputs=['a'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"__init__() missing 1 required positional argument: 'outputs'\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(outputs=['a'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"__init__() missing 1 required positional argument: 'inputs'\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a'], outputs=42)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"42 must be a list of strings\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=None, outputs=42)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"None must be a list of strings\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a', 42], outputs=['b'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"42 must be a string\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a', 'b'], outputs=['b'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Repeated item b\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['a'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Repeated item a\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a summary of the PDE inputs, outputs, params and bocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs (train):  {'x': [], 't': []}\n",
      "inputs (test):  {'x': [], 't': []}\n",
      "outputs:  {'p': []}\n",
      "params:  {'u': []}\n",
      "bocos:  []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pde = PDE(inputs=['x', 't'], outputs=['p'], params=['u'])\n",
    "\n",
    "pde.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve a PDE you must set some input values, and optionally free-parameters. You cannot set output values (this will be given by the neural network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d'])\n",
    "\n",
    "a = np.array([0, 0.5, 1])\n",
    "b = np.array([0, 0.5, 1])\n",
    "d = np.array([1.0])\n",
    "pde.setValues({'a': a, 'b': b, 'd': d})\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'c': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set values to outputs !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'e': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Key e not found !\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, values are set for training but you can specify values for testing (in this case only for inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d'])\n",
    "\n",
    "a = np.array([0, 0.5, 1])\n",
    "b = np.array([0, 0.5, 1])\n",
    "pde.setValues({'a': a, 'b': b}, train=False)\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'd': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set params in test data !\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d'])\n",
    "\n",
    "a = np.array([0, 0.5, 1])\n",
    "b = np.array([0, 0.5, 1])\n",
    "d = np.array([1.0])\n",
    "\n",
    "pde.setValues({'a': a})\n",
    "pde.setValues({'a': a, 'b': b, 'd': d})\n",
    "\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'c': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set values to outputs !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'e': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Key e not found !\", \"assertion failed\"\n",
    "    \n",
    "pde.setValues({'a': a, 'b': b}, train=False)\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'd': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set params in test data !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'c': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set values to outputs !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'e': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Key e not found !\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a boundary condition to the system, first define one and then add it with the *addBoco* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boco_name summary:\n",
      "Type: periodic\n",
      "Input 1:  {'a': array([0]), 'b': array([1, 2, 3])}\n",
      "Input 2:  {'a': array([1]), 'b': array([1, 2, 3])}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'])\n",
    "\n",
    "a1, a2 = np.array([0]), np.array([1])\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "boco = PeriodicBoco('boco_name', {'a': a1, 'b': b}, {'a': a2, 'b': b})\n",
    "pde.addBoco(boco)\n",
    "\n",
    "pde.bocoSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about Boundary Conditions at `bocos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to solve the PDE we need to build the solution. You can build a Multilayer Perceptron (MLP) to approximate the solution to the PDE as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'])\n",
    "\n",
    "# add values and bocos\n",
    "\n",
    "mlp = {'layers': 3, 'neurons': 100, 'activations': 'relu'}\n",
    "pde.buildSolution(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should pass a dictionary with the values for *layers, *neurons* and *activations* to define the MLP. Once the solution is defined we can set the training parameters with the `compile` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde.compile(lr=0.01, epochs=20, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the PDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the PDE is defined and compiled, we can solve it with the `solve` method. During the training the function `computePDELoss` will be called and it is expected to return a list with the correct loss functions in order to solve the PDEs. To that end, a custom PDE child class has to be defined to overload this particular function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/3 Losses 0.00001 \n",
       " PDE  [ 0.00001 ] <p>Epoch 2/3 Losses 0.00001 \n",
       " PDE  [ 0.00001 ] <p>Epoch 3/3 Losses 0.00000 \n",
       " PDE  [ 0.00000 ] "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# define custom PDE\n",
    "class MyPDE(PDE):\n",
    "    \"Custom PDE to solve: dp/da + dp/db = 0\"\n",
    "    def __init__(self, inputs, outputs, params=None):\n",
    "        super().__init__(inputs, outputs, params)\n",
    "    def computePDELoss(self, grads, inputs, outputs, params): \n",
    "        dpda, dpdb = grads['p']['a'], grads['p']['b']\n",
    "        return [dpda + dpdb]\n",
    "\n",
    "# instanciate your new custo PDE class\n",
    "pde = MyPDE(inputs=['a', 'b'], outputs=['p'])\n",
    "\n",
    "# set values\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "pde.setValues({'a': a, 'b': b})\n",
    "\n",
    "# find solution\n",
    "mlp = {'layers': 3, 'neurons': 10, 'activations': 'relu'}\n",
    "pde.buildSolution(mlp)\n",
    "pde.compile(lr=0.01, epochs=3, batch_size=2)\n",
    "hist = pde.solve(device=\"cpu\", path='best_solution.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the dataset class returns every possible combination of inputs, while the dataloader returns these in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [3., 5.]])\n",
      "tensor([[1., 6.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.]])\n",
      "tensor([[1., 5.],\n",
      "        [2., 4.]])\n",
      "tensor([[2., 6.]])\n"
     ]
    }
   ],
   "source": [
    "for i in pde.dataloader['train']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-order PDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve higher order PDEs, just define the order when the PDE is instanciated. Remember to use an activation function with non-zero high order derivatives, such as *sigmoid*. FOR NOW ONLY 2nd ORDER DERIVATIVES ARE SUPPORTED !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/3 Losses 0.00000 \n",
       " PDE  [ 0.00000 ] <p>Epoch 2/3 Losses 0.00000 \n",
       " PDE  [ 0.00000 ] <p>Epoch 3/3 Losses 0.00000 \n",
       " PDE  [ 0.00000 ] "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define custom PDE\n",
    "class MyPDE(PDE):\n",
    "    \"Custom PDE to solve: dp/da + dp/db -  d2p/da2 = 0\"\n",
    "    def __init__(self, inputs, outputs, params=None, order=2):\n",
    "        super().__init__(inputs, outputs, params, order)\n",
    "    def computePDELoss(self, grads, inputs, outputs, params): \n",
    "        dpda, dpdb = grads['p']['a'], grads['p']['b']\n",
    "        d2pda2 = grads['2p']['aa']\n",
    "        # other options\n",
    "        # d2pdab = grads['2p']['ab']\n",
    "        # d2pdab = grads['2p']['bb']\n",
    "        # d2pdba = grads['2p']['ba']\n",
    "        return [dpda + dpdb - d2pda2]\n",
    "\n",
    "# instanciate your new custo PDE class\n",
    "pde = MyPDE(inputs=['a', 'b'], outputs=['p'], order=2)\n",
    "\n",
    "# set values\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "pde.setValues({'a': a, 'b': b})\n",
    "\n",
    "# find solution\n",
    "mlp = {'layers': 3, 'neurons': 10, 'activations': 'sigmoid'}\n",
    "pde.buildSolution(mlp)\n",
    "pde.compile(lr=0.001, epochs=3, batch_size=32)\n",
    "hist = pde.solve(device=\"cpu\", path='best_solution.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systems of PDEs\n",
    "\n",
    "To solve a system of PDEs, just return one loss for each PDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 2/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 3/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 4/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 5/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 6/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 7/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 8/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 9/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 10/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define custom PDE\n",
    "class MyPDE(PDE):\n",
    "    \"\"\"Custom PDE to solve the system: \n",
    "        dp/da + dp/db = 0\n",
    "        dr/da + dr/db = 0\"\"\"\n",
    "    def __init__(self, inputs, outputs, params=None, order=2):\n",
    "        super().__init__(inputs, outputs, params, order)\n",
    "    def computePDELoss(self, grads, inputs, outputs, params): \n",
    "        dpda, dpdb = grads['p']['a'], grads['p']['b']\n",
    "        drda, drdb = grads['r']['a'], grads['r']['b']\n",
    "        return [\n",
    "            dpda + dpdb,\n",
    "            drda + drdb\n",
    "        ]\n",
    "\n",
    "# instanciate your new custo PDE class\n",
    "pde = MyPDE(inputs=['a', 'b'], outputs=['p', 'r'], order=2)\n",
    "\n",
    "# set values\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "pde.setValues({'a': a, 'b': b})\n",
    "\n",
    "# find solution\n",
    "mlp = {'layers': 3, 'neurons': 10, 'activations': 'sigmoid'}\n",
    "pde.buildSolution(mlp)\n",
    "pde.compile(lr=0.001, epochs=10, batch_size=32)\n",
    "hist = pde.solve(device=\"cpu\", path='best_solution.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom gradients\n",
    "\n",
    "In some cases you may want to compute other gradients than just the ones for the ouputs w.r.t the inputs (e.g. you may want the derivatives of some combinations of the outputs and parameters). You can do so by calling the *computeGrad* function which will compute the derivatives w.r.t the specified input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 2/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 3/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 4/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 5/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 6/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 7/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 8/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 9/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] <p>Epoch 10/10 Losses 0.00000 \n",
       " PDE  [ 0.00000 0.00000 ] "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyPDE(PDE):\n",
    "    \"\"\"Custom PDE to solve the system: \n",
    "        dp/da + ds/db = 0\n",
    "        dr/da + ds/db = 0\n",
    "        where s = p*r\"\"\"\n",
    "    def __init__(self, inputs, outputs, params=None, order=2):\n",
    "        super().__init__(inputs, outputs, params, order)\n",
    "    def computePDELoss(self, grads, inputs, outputs, params): \n",
    "        dpda = grads['p']['a']\n",
    "        drda = grads['r']['a']\n",
    "        p, r = outputs['p'], outputs['r']\n",
    "        s = p*r\n",
    "        # compute custom gradient\n",
    "        dsdb = self.computeGrad(s, 'b')\n",
    "        return [\n",
    "            dpda + dsdb,\n",
    "            drda + dsdb\n",
    "        ]\n",
    "\n",
    "# instanciate your new custo PDE class\n",
    "pde = MyPDE(inputs=['a', 'b'], outputs=['p', 'r'], order=2)\n",
    "\n",
    "# set values\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "pde.setValues({'a': a, 'b': b})\n",
    "\n",
    "# find solution\n",
    "mlp = {'layers': 3, 'neurons': 10, 'activations': 'sigmoid'}\n",
    "pde.buildSolution(mlp)\n",
    "pde.compile(lr=0.001, epochs=10, batch_size=32)\n",
    "hist = pde.solve(device=\"cpu\", path='best_solution.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
