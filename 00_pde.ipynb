{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from nangs.bocos import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDE\n",
    "\n",
    "> This module contains the PDE class with the basic functionality to solve PDEs with NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from nangs.utils import *\n",
    "from nangs.solution import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import numpy as np\n",
    "\n",
    "class PDEDataset(Dataset):\n",
    "    \"Receives a dict of arrays and returns every possible combination of the elements in the arrays\"\n",
    "    def __init__(self, inputs):\n",
    "        # convert dict to array\n",
    "        self.inputs = np.array([inputs[k] for k in inputs])\n",
    "        # length of the dataset (all possible combinations)\n",
    "        self.len = 1\n",
    "        for input in self.inputs:\n",
    "            self.len *= len(input)\n",
    "        # modules\n",
    "        self.mods = []\n",
    "        for i, _ in enumerate(self.inputs):\n",
    "            mod = 1\n",
    "            for j, input in enumerate(self.inputs):\n",
    "                if j < i:\n",
    "                    mod *= len(input)\n",
    "            self.mods.append(mod)  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor([inp[(idx // self.mods[i]) % len(inp)] for i, inp in enumerate(self.inputs)])\n",
    "\n",
    "class PDE:\n",
    "    \"PDE class with basic functionality to solve PDEs with NNs\"\n",
    "    def __init__(self, inputs, outputs, params=None):\n",
    "        \n",
    "        # check lists of unique strings, non-repeated\n",
    "        checkIsListOfStr(inputs)\n",
    "        checkUnique(inputs)\n",
    "        checkIsListOfStr(outputs)\n",
    "        checkUnique(outputs)\n",
    "        checkNoRepeated(inputs, outputs)\n",
    "        if params:\n",
    "            checkIsListOfStr(params)\n",
    "            checkUnique(params)\n",
    "            checkNoRepeated(inputs, params)\n",
    "            checkNoRepeated(params, outputs)\n",
    "        \n",
    "        # save keys\n",
    "        self.input_keys = inputs\n",
    "        self.output_keys = outputs\n",
    "        self.param_keys = params            \n",
    "        \n",
    "        # initialize values\n",
    "        self.train_inputs = {k: [] for k in self.input_keys}\n",
    "        self.test_inputs = {k: [] for k in self.input_keys}\n",
    "        self.outputs = {k: [] for k in self.output_keys}\n",
    "        self.params = {}\n",
    "        if self.param_keys:\n",
    "            self.params = {k: [] for k in self.param_keys}\n",
    "        \n",
    "        # bocos\n",
    "        self.bocos = []\n",
    "        \n",
    "        self.init = False\n",
    "\n",
    "    def summary(self):\n",
    "        \"Print a summary of the PDE inputs, outputs, params and bocos.\"\n",
    "        print('inputs (train): ', self.train_inputs)\n",
    "        print('inputs (test): ', self.test_inputs)\n",
    "        print('outputs: ', self.outputs)\n",
    "        if self.params:\n",
    "            print('params: ', self.params)\n",
    "        print('bocos: ', [boco.type for boco in self.bocos])\n",
    "        print('')\n",
    "        \n",
    "    def setValues(self, values, train=True):\n",
    "        \"Set values for inputs and params\"\n",
    "        checkValidDict(values)\n",
    "        for key in values:\n",
    "            value = values[key]\n",
    "            if key in self.input_keys: \n",
    "                if train: \n",
    "                    self.train_inputs[key] = value\n",
    "                else: \n",
    "                    self.test_inputs[key] = value\n",
    "            elif key in self.param_keys: \n",
    "                if train:    \n",
    "                    self.params[key] = value\n",
    "                else: \n",
    "                    raise Exception('You cannot set params in test data !')\n",
    "            elif key in self.output_keys:\n",
    "                raise Exception('You cannot set values to outputs !')\n",
    "            else:\n",
    "                raise Exception('Key '+ key +' not found !')\n",
    "                \n",
    "    def addBoco(self, boco):\n",
    "        \"Add a boco to the list of bocos\"\n",
    "        boco.addBoco(self.input_keys, self.output_keys)\n",
    "        self.bocos += [boco]\n",
    "        \n",
    "    def bocoSummary(self):\n",
    "        \"Print summary of each boco\"\n",
    "        for boco in self.bocos: \n",
    "            boco.summary(self.input_keys, self.output_keys, self.param_keys) \n",
    "            \n",
    "    def buildSolution(self, topo):\n",
    "        \"Build an MLP to be the solution to the PDE\"\n",
    "        n_inputs, n_outputs = len(self.input_keys), len(self.output_keys)\n",
    "        self.solution = Solution(n_inputs, n_outputs, topo['layers'], topo['neurons'], topo['activations'])\n",
    "\n",
    "    def compile(self, lr=0.001, epochs=100, batch_size=32):\n",
    "        \"Set the required parameters for training\"\n",
    "        self.optimizer = torch.optim.Adam(self.solution.parameters(), lr=lr)\n",
    "        self.epochs = epochs\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def solve(self, device, path):\n",
    "        \"Find a solution to the PDE\"\n",
    "        # initialize dataladers\n",
    "        if not self.init: \n",
    "            self.initialize()\n",
    "        # convert params to tensors\n",
    "        params = {k: torch.FloatTensor(self.params[k]).to(device) for k in self.params}\n",
    "        # train loop\n",
    "        self.solution.to(device)\n",
    "        best_loss = 1e8\n",
    "        hist = {'train_loss': [], 'val_loss': [], 'bocos': {boco.name: [] for boco in self.bocos}}\n",
    "        mb = master_bar(range(1, self.epochs+1))\n",
    "        for epoch in mb:\n",
    "            #train\n",
    "            self.solution.train()\n",
    "            pde_loss = []\n",
    "            bocos_loss = {boco.name: [] for boco in self.bocos}\n",
    "            for inputs in progress_bar(self.dataloader['train'], parent=mb):\n",
    "                # compute pde solution\n",
    "                inputs = inputs.to(device)\n",
    "                inputs.requires_grad = True\n",
    "                #print(inputs.require_grad)\n",
    "                outputs = self.solution(inputs)\n",
    "                # compute gradients of outputs w.r.t. inputs\n",
    "                grads, _inputs = self.computeGrads(inputs, outputs)\n",
    "                # compute loss\n",
    "                loss = self.computePDELoss(grads, _inputs, params).pow(2).mean()\n",
    "                pde_loss.append(loss.item())\n",
    "                # compute bocos loss\n",
    "                # compute loss for all boco points at once (1 batch each b.c, optimize all together)\n",
    "                for boco in self.bocos:\n",
    "                    boco_loss = boco.computeLoss(self.solution, device)\n",
    "                    bocos_loss[boco.name].append(boco_loss.item())\n",
    "                    loss += boco_loss\n",
    "                # update weights\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                mb.child.comment = f'train loss {np.mean(pde_loss):.5f}'\n",
    "            \n",
    "            #evaluate\n",
    "            self.solution.eval()\n",
    "            val_loss = []\n",
    "            for inputs in progress_bar(self.dataloader['val'], parent=mb):\n",
    "                # compute pde solution\n",
    "                inputs = inputs.to(device)\n",
    "                inputs.requires_grad = True\n",
    "                outputs = self.solution(inputs)\n",
    "                # compute gradients of outputs w.r.t. inputs\n",
    "                grads, _inputs = self.computeGrads(inputs, outputs)\n",
    "                # compute loss\n",
    "                loss = self.computePDELoss(grads, _inputs, params).pow(2).mean()\n",
    "                val_loss.append(loss.item())\n",
    "                mb.child.comment = f'val loss {np.mean(val_loss):.5f}'\n",
    "\n",
    "            pde_total_loss = np.mean(pde_loss)\n",
    "            val_total_loss = np.mean(val_loss)\n",
    "            bocos_total_loss = 0\n",
    "            for boco in self.bocos:\n",
    "                bocos_loss[boco.name] = np.mean(bocos_loss[boco.name])\n",
    "                hist['bocos'][boco.name].append(bocos_loss[boco.name])\n",
    "                bocos_total_loss += bocos_loss[boco.name]\n",
    "            total_loss = pde_total_loss + bocos_total_loss\n",
    "            \n",
    "            if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                torch.save(self.solution.state_dict(), path)\n",
    "            \n",
    "            hist['train_loss'].append(total_loss)\n",
    "            hist['val_loss'].append(val_total_loss)\n",
    "            \n",
    "            info = f'Epoch {epoch}/{self.epochs} Losses {total_loss:.5f} \\n PDE  {pde_total_loss:.5f}'\n",
    "            for boco in self.bocos:\n",
    "                info += f'\\n {boco.name} {bocos_loss[boco.name]:.5f}'\n",
    "            info += f'\\n Val {val_total_loss:.5f} '\n",
    "            mb.write(info)          \n",
    "            #mb.first_bar.comment = f'best acc {best_acc:.5f} at epoch {best_e}'\n",
    "            \n",
    "        return hist\n",
    "                \n",
    "    def initialize(self):\n",
    "        self.dataset = {\n",
    "            'train': PDEDataset(self.train_inputs),\n",
    "            'val': PDEDataset(self.test_inputs)\n",
    "        } \n",
    "        self.dataloader = {\n",
    "            'train': DataLoader(self.dataset['train'], batch_size=self.bs, shuffle=True, num_workers=4),\n",
    "            'val': DataLoader(self.dataset['val'], batch_size=self.bs, shuffle=False, num_workers=4)\n",
    "        }\n",
    "        for boco in self.bocos:\n",
    "            boco.initialize()\n",
    "        self.init = True\n",
    "                        \n",
    "    def computeGrads(self, inputs, outputs):\n",
    "        # compute gradients\n",
    "        _grads, = torch.autograd.grad(outputs, inputs, \n",
    "                    grad_outputs=outputs.data.new(outputs.shape).fill_(1),\n",
    "                    create_graph=True, only_inputs=True)\n",
    "        # assign keys to gradients\n",
    "        grads = {output: {\n",
    "            inp: _grads[:,j] for j, inp in enumerate(self.input_keys)\n",
    "        } for output in self.output_keys}\n",
    "        # assign keys to inputs\n",
    "        _inputs = {inp: inputs[:,i] for i, inp in enumerate(self.input_keys)}\n",
    "        return grads, _inputs\n",
    "                        \n",
    "    def computePDELoss(self, inputs, outputs, params=None):\n",
    "        print('This function has to be overloaded by a child class!')\n",
    "        \n",
    "    def load_state_dict(self, path):\n",
    "        self.solution.load_state_dict(torch.load(path))\n",
    "        \n",
    "    def eval(self, inputs, device):\n",
    "        \"Evaluate solution\"\n",
    "        checkValidDict(inputs)\n",
    "        checkDictArray(inputs, self.input_keys)\n",
    "        # set values of inpenedent vars \n",
    "        for key in self.input_keys: \n",
    "            if key in inputs: \n",
    "                self.test_inputs[key] = inputs[key] \n",
    "            else: \n",
    "                raise Exception(key + ' is not an input')\n",
    "        # build dataset\n",
    "        dataset = PDEDataset(self.test_inputs)\n",
    "        outputs = []\n",
    "        self.solution.eval()\n",
    "        for i in range(len(dataset)):\n",
    "            input = dataset[i].to(device)\n",
    "            outputs.append(self.solution(input).cpu().detach().numpy())\n",
    "        return np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['x', 't'], outputs=['p'], params=['u'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*inputs*, *outputs* and *params* must be lists of strings with non-repeated elements or you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pde = PDE(inputs=['x', 't'], outputs=['x'], params=['u'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Repeated item x\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "pde = PDE(['a'], ['b'])\n",
    "pde = PDE(inputs=['a'], outputs=['b'])\n",
    "pde = PDE(inputs=['a', 'b', 'c'], outputs=['d'])\n",
    "pde = PDE(inputs=['a'], outputs=['b', 'c', 'd'])\n",
    "pde = PDE(inputs=['a'], outputs=['b'], params=['c'])\n",
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d', 'e', 'f'])\n",
    "\n",
    "try:\n",
    "    pde = PDE(inputs=['a'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"__init__() missing 1 required positional argument: 'outputs'\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(outputs=['a'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"__init__() missing 1 required positional argument: 'inputs'\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a'], outputs=42)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"42 must be a list of strings\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=None, outputs=42)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"None must be a list of strings\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a', 42], outputs=['b'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"42 must be a string\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a', 'b'], outputs=['b'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Repeated item b\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['a'])\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Repeated item a\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a summary of the PDE inputs, outputs, params and bocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs (train):  {'x': [], 't': []}\n",
      "inputs (test):  {'x': [], 't': []}\n",
      "outputs:  {'p': []}\n",
      "params:  {'u': []}\n",
      "bocos:  []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pde = PDE(inputs=['x', 't'], outputs=['p'], params=['u'])\n",
    "\n",
    "pde.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve a PDE you must set some input values, and optionally free-parameters. You cannot set output values (this will be given by the neural network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d'])\n",
    "\n",
    "a = np.array([0, 0.5, 1])\n",
    "b = np.array([0, 0.5, 1])\n",
    "d = np.array([1.0])\n",
    "pde.setValues({'a': a, 'b': b, 'd': d})\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'c': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set values to outputs !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'e': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Key e not found !\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, values are set for training but you can specify values for testing (in this case only for inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d'])\n",
    "\n",
    "a = np.array([0, 0.5, 1])\n",
    "b = np.array([0, 0.5, 1])\n",
    "pde.setValues({'a': a, 'b': b}, train=False)\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'd': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set params in test data !\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "pde = PDE(inputs=['a', 'b'], outputs=['c'], params=['d'])\n",
    "\n",
    "a = np.array([0, 0.5, 1])\n",
    "b = np.array([0, 0.5, 1])\n",
    "d = np.array([1.0])\n",
    "\n",
    "pde.setValues({'a': a})\n",
    "pde.setValues({'a': a, 'b': b, 'd': d})\n",
    "\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'c': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set values to outputs !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'e': d})\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Key e not found !\", \"assertion failed\"\n",
    "    \n",
    "pde.setValues({'a': a, 'b': b}, train=False)\n",
    "\n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'd': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set params in test data !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'c': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"You cannot set values to outputs !\", \"assertion failed\"\n",
    "    \n",
    "try:\n",
    "    pde.setValues({'a': a, 'b': b, 'e': d}, train=False)\n",
    "except Exception as e:\n",
    "    assert str(e) == \"Key e not found !\", \"assertion failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a boundary condition to the system, first define one and then add it with the *addBoco* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boco_name summary:\n",
      "Type: periodic\n",
      "Input 1:  {'a': 'a', 'b': 'b'}\n",
      "Input 2:  {'a': 'a', 'b': 'b'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'])\n",
    "\n",
    "a1, a2 = np.array([0]), np.array([1])\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "boco = PeriodicBoco('boco_name', {'a': a1, 'b': b}, {'a': a2, 'b': b})\n",
    "pde.addBoco(boco)\n",
    "\n",
    "pde.bocoSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about Boundary Conditions at `bocos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to solve the PDE we need to build the solution. You can build a Multilayer Perceptron (MLP) to approximate the solution to the PDE as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = PDE(inputs=['a', 'b'], outputs=['c'])\n",
    "\n",
    "# add values and bocos\n",
    "\n",
    "mlp = {'layers': 3, 'neurons': 100, 'activations': 'relu'}\n",
    "pde.buildSolution(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should pass a dictionary with the values for *layers, *neurons* and *activations* to define the MLP. Once the solution is defined we can set the training parameters with the `compile` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde.compile(lr=0.01, epochs=20, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the PDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the PDE is defined and compiled, we can solve it with the `solve` method. During the training the function `computePDELoss` will be called and it is expected to return the correct loss function in order to solve the PDE. To that end, a custom PDE child class has to be defined to overload this particular function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/3 : loss=0.00027<p>Epoch 2/3 : loss=0.00004<p>Epoch 3/3 : loss=0.00006"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define custom PDE\n",
    "class MyPDE(PDE):\n",
    "    \"Custom PDE to solve: dp/da + dp/db = 0\"\n",
    "    def __init__(self, inputs, outputs, params=None):\n",
    "        super().__init__(inputs, outputs, params)\n",
    "    def computePDELoss(self, grads, inputs, params): \n",
    "        dpda, dpda = grads['p']['a'], grads['p']['b']\n",
    "        return dpda + dpda\n",
    "\n",
    "# instanciate your new custo PDE class\n",
    "pde = MyPDE(inputs=['a', 'b'], outputs=['p'])\n",
    "\n",
    "# set values\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "pde.setValues({'a': a, 'b': b})\n",
    "\n",
    "# find solution\n",
    "mlp = {'layers': 3, 'neurons': 10, 'activations': 'relu'}\n",
    "pde.buildSolution(mlp)\n",
    "pde.compile(lr=0.01, epochs=3, batch_size=2)\n",
    "pde.solve(device=\"cpu\", path='best_solution.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the dataset class returns every possible combination of inputs, while the dataloader returns these in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [3., 5.]])\n",
      "tensor([[2., 5.],\n",
      "        [3., 4.]])\n",
      "tensor([[2., 6.],\n",
      "        [1., 5.]])\n",
      "tensor([[3., 6.],\n",
      "        [2., 4.]])\n",
      "tensor([[1., 6.]])\n"
     ]
    }
   ],
   "source": [
    "for i in pde.dataloader['train']:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
